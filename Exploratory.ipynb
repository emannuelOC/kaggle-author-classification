{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import merge\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Reshape, Convolution2D, MaxPooling2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = df['text'], df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 19579)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding: generate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(string_list):\n",
    "    print(string_list)\n",
    "    new_list = [clean(nltk.word_tokenize(s)) for s in string_list]\n",
    "    return new_list\n",
    "\n",
    "def clean(sentence, stop_words=[], lemm=WordNetLemmatizer()):\n",
    "    return [x.lower() for x in sentence if x.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emannuelcarvalho/.virtualenvs/ml/lib/python2.7/site-packages/ipykernel_launcher.py:7: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'told', u'alre\\ufffd\\ufffddy', u'car', u'look', u'nice']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(nltk.word_tokenize(\"I told you alre√¶dy that the car looks nice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in X_train:\n",
    "    print s\n",
    "    process([unicode(s, errors='replace')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "sentences = process([x for x in X_train])\n",
    "vector_size = 70\n",
    "model = Word2Vec(sentences, size=vector_size, window=10, min_count=1, workers=4)\n",
    "word_vectors = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_word(word):\n",
    "    try:\n",
    "        return word_vectors[word.strip(',.!?\\'\"').strip(',.!?\\'\"').lower()]\n",
    "    except:\n",
    "        return word_vectors['the']\n",
    "                            \n",
    "\n",
    "def vectorize(text):\n",
    "    return [vectorize_word(w) for w in text.split()]\n",
    "\n",
    "X_train_vec = [vectorize(text) for text in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579\n",
      "19579\n"
     ]
    }
   ],
   "source": [
    "print len(y_train)\n",
    "y_train = [{'EAP': 0, 'HPL': 1, 'MWS': 2}[y] for y in y_train]\n",
    "print len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vec = np.array(X_train_vec)\n",
    "y_train = to_categorical(np.array(y_train), num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npML9H6OKZG7XFz56AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125595450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.array([len(x) for x in X_train_vec])\n",
    "plt.boxplot(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "X_train = X_train_vec\n",
    "max_length = 200\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 200, 70) (19579, 3)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'show', 0.982287585735321),\n",
       " (u'god', 0.9796628355979919),\n",
       " (u'word', 0.9752758741378784),\n",
       " (u'pretty', 0.9736962914466858),\n",
       " (u\"'t\", 0.9734954833984375),\n",
       " (u'yours', 0.9676824808120728),\n",
       " (u'valor', 0.9633820652961731),\n",
       " (u'quite', 0.9613347053527832),\n",
       " (u'foolish', 0.9610820412635803),\n",
       " (u'write', 0.9584431648254395)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 200, 70)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "nsamples, nx, ny = X_train.shape\n",
    "d2_X_train = X_train.reshape((nsamples,nx*ny))\n",
    "d2_X_train = Normalizer(copy=False).fit_transform(d2_X_train)\n",
    "d2_X_train += 1.0\n",
    "d1_y_train = [{'EAP': 0, 'HPL': 1, 'MWS': 2}[y] for y in df['author']]\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(d2_X_train, d1_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "X_test_text = test_df['text']\n",
    "X_test = [vectorize(text) for text in X_test_text]\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)\n",
    "nsamples, nx, ny = X_test.shape\n",
    "d2_X_test = X_test.reshape((nsamples,nx*ny))\n",
    "d2_X_test = Normalizer(copy=False).fit_transform(d2_X_test)\n",
    "d2_X_test += 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids, y_test = [i for i in test_df['id']], clf.predict_proba(d2_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40213821,  0.28979128,  0.30807051])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emannuelcarvalho/.virtualenvs/ml/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(512, activation=\"relu\", kernel_initializer=\"uniform\", input_shape=(200, 70))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13117 samples, validate on 6462 samples\n",
      "Epoch 1/10\n",
      "13117/13117 [==============================] - 194s - loss: 1.0369 - acc: 0.4656 - val_loss: 0.9780 - val_acc: 0.5378\n",
      "Epoch 2/10\n",
      "13117/13117 [==============================] - 184s - loss: 0.9673 - acc: 0.5478 - val_loss: 0.9282 - val_acc: 0.5590\n",
      "Epoch 3/10\n",
      "13117/13117 [==============================] - 186s - loss: 0.9176 - acc: 0.5824 - val_loss: 0.8910 - val_acc: 0.5853\n",
      "Epoch 4/10\n",
      "13117/13117 [==============================] - 190s - loss: 0.8836 - acc: 0.6061 - val_loss: 0.8744 - val_acc: 0.6040\n",
      "Epoch 5/10\n",
      "13117/13117 [==============================] - 185s - loss: 0.8549 - acc: 0.6270 - val_loss: 0.8933 - val_acc: 0.6035\n",
      "Epoch 6/10\n",
      "13117/13117 [==============================] - 184s - loss: 0.8402 - acc: 0.6345 - val_loss: 0.9172 - val_acc: 0.6051\n",
      "Epoch 7/10\n",
      "13117/13117 [==============================] - 189s - loss: 0.8256 - acc: 0.6399 - val_loss: 0.9647 - val_acc: 0.5591\n",
      "Epoch 8/10\n",
      "13117/13117 [==============================] - 189s - loss: 0.8177 - acc: 0.6549 - val_loss: 0.8928 - val_acc: 0.6148\n",
      "Epoch 9/10\n",
      "13117/13117 [==============================] - 189s - loss: 0.8191 - acc: 0.6482 - val_loss: 0.8740 - val_acc: 0.6011\n",
      "Epoch 10/10\n",
      "13117/13117 [==============================] - 191s - loss: 0.8021 - acc: 0.6563 - val_loss: 0.9019 - val_acc: 0.6144\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(200, 70), init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.33, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48820114  0.15095983  0.36083898]] [ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.array([X_train[3]]))\n",
    "print prediction, y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "X_test_text = test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = [vectorize(text) for text in X_test_text]\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids, y_test = [i for i in test_df['id']], model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,EAP,HPL,MWS\n",
      "id02310,0.0450474508107,0.0615367554128,0.893415808678\n",
      "id24541,0.969961106777,0.0161529406905,0.0138858770952\n",
      "id00134,0.0378526486456,0.716230392456,0.245916977525\n",
      "id27757,0.83968108892\n"
     ]
    }
   ],
   "source": [
    "# submission_file = open('submission1.csv', 'w')\n",
    "file_text = \"\"\n",
    "file_text += \"id,EAP,HPL,MWS\\n\"\n",
    "for data in zip(ids, y_test):\n",
    "    file_text += \"{},{},{},{}\\n\".format(data[0], data[1][0], data[1][1], data[1][2])\n",
    "print(file_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-7f4b9925c320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmission_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission4.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubmission_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubmission_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_text' is not defined"
     ]
    }
   ],
   "source": [
    "submission_file = open('submission4.csv', 'w')\n",
    "submission_file.write(file_text)\n",
    "submission_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
